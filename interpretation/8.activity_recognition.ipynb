{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5137e91-0a20-4613-b60e-449d27218d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from py_session import py_session\n",
    "import pandas as pd\n",
    "import random\n",
    "import re\n",
    "import os\n",
    "import tempfile\n",
    "import ssl\n",
    "import cv2\n",
    "import numpy as np\n",
    "import imageio\n",
    "from IPython import display\n",
    "from urllib import request\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1eb82da-6d67-43bc-b804-2aeefbbbf636",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_video(path, max_seconds = 60, resize = (224, 224)):\n",
    "    frames = []\n",
    "\n",
    "    vidcap = cv2.VideoCapture(path)\n",
    "    fps = vidcap.get(cv2.CAP_PROP_FPS) # sample 1 frame per second \n",
    "\n",
    "    count = 0\n",
    "\n",
    "    while vidcap.isOpened():\n",
    "        sucess, frame = vidcap.read()\n",
    "        #frame = cv2.resize(frame, (224, 224))\n",
    "\n",
    "        if sucess and count <= fps*(max_seconds - 1):\n",
    "            #cv2.imwrite('frame%d.jpg' % count, frame)\n",
    "            frame = cv2.resize(frame, resize)\n",
    "            frames.append(frame)\n",
    "            count +=  (fps/1) # this advances one second\n",
    "            vidcap.set(1, count)\n",
    "        else:\n",
    "            vidcap.release()\n",
    "            break\n",
    "\n",
    "    return np.array(frames) / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5498a61-fc91-4e70-bebe-1097c546a268",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_dir = '/n/holylfs05/LABS/jyang_lab/Lab/tiktok_sample/sales_panel/video/'\n",
    "video_name = os.listdir(video_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6eea9ab-ae87-4827-b1bd-d301618a9d11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400 labels.\n"
     ]
    }
   ],
   "source": [
    "# Get the kinetics-400 action labels from the GitHub repository.\n",
    "KINETICS_URL = \"https://raw.githubusercontent.com/deepmind/kinetics-i3d/master/data/label_map.txt\"\n",
    "with request.urlopen(KINETICS_URL) as obj:\n",
    "  labels = [line.decode(\"utf-8\").strip() for line in obj.readlines()]\n",
    "print(\"Found %d labels.\" % len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e7439c2-b7bd-46b9-9043-72a7a074c338",
   "metadata": {},
   "outputs": [],
   "source": [
    "i3d = hub.load(\"https://tfhub.dev/deepmind/i3d-kinetics-400/1\").signatures['default']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "55cf6033-8a73-4a24-b98d-8578537c91d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(sample_video):\n",
    "  act = []\n",
    "  prob = []\n",
    "  # Add a batch axis to the sample video.\n",
    "  model_input = tf.constant(sample_video, dtype=tf.float32)[tf.newaxis, ...]\n",
    "\n",
    "  logits = i3d(model_input)['default'][0]\n",
    "  probabilities = tf.nn.softmax(logits)\n",
    "\n",
    "  #print(\"Top 5 actions:\")\n",
    "  for i in np.argsort(probabilities)[::-1][:5]:\n",
    "        act.append(labels[i])\n",
    "        prob.append(probabilities[i].numpy() * 100)\n",
    "  return(act, prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e71e745-74cd-4100-8fe2-da4e212791d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "\n",
    "splitedSize = 15\n",
    "\n",
    "for i in range(len(video_name)):\n",
    "    sample_video = load_video(video_dir + video_name[i])\n",
    "    sample_video_splited = [sample_video[x:x+splitedSize] for x in range(0, len(sample_video), splitedSize)]\n",
    "    \n",
    "    for j in range(len(sample_video_splited)):\n",
    "        act = predict(sample_video_splited[j])\n",
    "        d = pd.DataFrame()\n",
    "        d['activity'] = act[0]\n",
    "        d['rank'] = range(1,6)\n",
    "        d['prob'] = act[1]\n",
    "        d['video_full_id'] = video_name[i]\n",
    "        d['split'] = j\n",
    "        df = df.append(d, ignore_index=True)\n",
    "    \n",
    "df.to_csv('/n/holylfs05/LABS/jyang_lab/Lab/tiktok_sample/sales_panel/activity/activity.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9ea71523-f94a-4501-9343-df842d8d6ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# py_session()\n",
    "# 59 modules found\n",
    "# IPython             \t7.22.0                  idna                \t2.10                    pygments            \t2.8.1\n",
    "# PIL                 \t8.2.0                   imageio             \t2.9.0                   pytz                \t2021.1\n",
    "# argparse            \t1.1                     ipykernel           \t5.3.4                   re                  \t2.2.1\n",
    "# astunparse          \t1.6.3                   ipython_genutils    \t0.2.0                   requests            \t2.31.0\n",
    "# backcall            \t0.2.0                   jedi                \t0.17.2                  scipy               \t1.6.2\n",
    "# bottleneck          \t1.3.2                   json                \t2.0.9                   six                 \t1.15.0\n",
    "# certifi             \t2020.12.05              jupyter_client      \t6.1.12                  socks               \t1.7.1\n",
    "# cffi                \t1.14.5                  jupyter_core        \t4.7.1                   tblib               \t1.7.0\n",
    "# chardet             \t4.0.0                   keras_preprocessing \t1.1.2                   tensorboard         \t2.11.2\n",
    "# charset_normalizer  \t3.3.2                   logging             \t0.5.1.2                 tensorflow          \t2.5.0\n",
    "# colorama            \t0.4.4                   numpy               \t1.22.4                  tensorflow_hub      \t0.15.0\n",
    "# csv                 \t1.0                     opt_einsum          \tv3.3.0                  termcolor           \t(1, 1, 0)\n",
    "# ctypes              \t1.1.0                   pandas              \t1.2.4                   traitlets           \t5.0.5\n",
    "# cv2                 \t4.8.1                   parso               \t0.7.0                   urllib3             \t1.26.4\n",
    "# dateutil            \t2.8.1                   pexpect             \t4.8.0                   wcwidth             \t0.2.5\n",
    "# decimal             \t1.70                    pickleshare         \t0.7.5                   wrapt               \t1.12.1\n",
    "# decorator           \t4.4.2                   platform            \t1.0.8                   yaml                \t5.4.1\n",
    "# distutils           \t3.8.8                   prompt_toolkit      \t3.0.17                  zlib                \t1.0\n",
    "# fsspec              \t0.9.0                   ptyprocess          \t0.7.0                   zmq                 \t20.0.0\n",
    "# h5py                \t3.1.0                   py_session          \t0.1.1                   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
