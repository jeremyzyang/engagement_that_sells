{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc70313b-ff33-4780-b0fd-d263f38b492a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from py_session import py_session\n",
    "import os\n",
    "import struct\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import natsort\n",
    "import cv2\n",
    "from skimage.transform import rescale, resize, downscale_local_mean\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.layers import ZeroPadding2D\n",
    "from tensorflow.keras.layers import UpSampling2D\n",
    "from tensorflow.keras.layers import add, concatenate\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d758eee9-403a-4416-b8e6-671c458fc2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_dir = '/n/holylfs05/LABS/jyang_lab/Lab/tiktok_sample/sales_panel/frame/'\n",
    "video_name = os.listdir(video_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9cc9d4d-bf04-4c71-9d09-d1cd705c4958",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build frames with only high engagement pixels\n",
    "\n",
    "length = 224\n",
    "width = 224\n",
    "\n",
    "for v in video_name:\n",
    "    video = video_dir + v\n",
    "    \n",
    "    count = 0\n",
    "    y = []\n",
    "\n",
    "    frame_name = os.listdir(video)\n",
    "    frame_name = natsort.natsorted(frame_name)\n",
    "    \n",
    "    if len(frame_name) < 1:\n",
    "        next\n",
    "    else:       \n",
    "        for frame in frame_name:\n",
    "            if not frame.startswith('.'):\n",
    "                image = cv2.imread(video + '/' + frame)\n",
    "                image = resize(image , (length,width))\n",
    "                y.append(image)\n",
    "                count+=1\n",
    "    y = np.array(y)\n",
    "    \n",
    "    enga = np.load('/n/holylfs05/LABS/jyang_lab/Lab/tiktok_sample/sales_panel/engagement_heatmap/' + v + '.npy')\n",
    "    f = 1*(enga >= np.median(enga))\n",
    "    \n",
    "    y1 = np.multiply(y[:,:,:,0], f)\n",
    "    y2 = np.multiply(y[:,:,:,1], f)\n",
    "    y3 = np.multiply(y[:,:,:,2], f)\n",
    "    \n",
    "    e = np.stack((y1,y2,y3),3)\n",
    "    \n",
    "    out = '/n/holylfs05/LABS/jyang_lab/Lab/tiktok_sample/sales_panel/frame_high_engagement/' + v\n",
    "    np.save(out, e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "502333ec-0422-4bf3-9076-feb74a75bc68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build frames with only low engagement pixels\n",
    "\n",
    "length = 224\n",
    "width = 224\n",
    "\n",
    "for v in video_name:\n",
    "    video = video_dir + v\n",
    "    \n",
    "    count = 0\n",
    "    y = []\n",
    "\n",
    "    frame_name = os.listdir(video)\n",
    "    frame_name = natsort.natsorted(frame_name)\n",
    "    \n",
    "    if len(frame_name) < 1:\n",
    "        next\n",
    "    else:       \n",
    "        for frame in frame_name:\n",
    "            if not frame.startswith('.'):\n",
    "                image = cv2.imread(video + '/' + frame)\n",
    "                image = resize(image , (length,width))\n",
    "                y.append(image)\n",
    "                count+=1\n",
    "    y = np.array(y)\n",
    "    \n",
    "    enga = np.load('/n/holylfs05/LABS/jyang_lab/Lab/tiktok_sample/sales_panel/engagement_heatmap/' + v + '.npy')\n",
    "    f = 1*(enga < np.median(enga))\n",
    "    \n",
    "    y1 = np.multiply(y[:,:,:,0], f)\n",
    "    y2 = np.multiply(y[:,:,:,1], f)\n",
    "    y3 = np.multiply(y[:,:,:,2], f)\n",
    "    \n",
    "    e = np.stack((y1,y2,y3),3)\n",
    "    \n",
    "    out = '/n/holylfs05/LABS/jyang_lab/Lab/tiktok_sample/sales_panel/frame_low_engagement/' + v\n",
    "    np.save(out, e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff9d6ad0-b082-4da2-9297-58e2f1493324",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _conv_block(inp, convs, skip=True):\n",
    "\tx = inp\n",
    "\tcount = 0\n",
    "\tfor conv in convs:\n",
    "\t\tif count == (len(convs) - 2) and skip:\n",
    "\t\t\tskip_connection = x\n",
    "\t\tcount += 1\n",
    "\t\tif conv['stride'] > 1: x = ZeroPadding2D(((1,0),(1,0)))(x) # peculiar padding as darknet prefer left and top\n",
    "\t\tx = Conv2D(conv['filter'],\n",
    "\t\t\t\t   conv['kernel'],\n",
    "\t\t\t\t   strides=conv['stride'],\n",
    "\t\t\t\t   padding='valid' if conv['stride'] > 1 else 'same', # peculiar padding as darknet prefer left and top\n",
    "\t\t\t\t   name='conv_' + str(conv['layer_idx']),\n",
    "\t\t\t\t   use_bias=False if conv['bnorm'] else True)(x)\n",
    "\t\tif conv['bnorm']: x = BatchNormalization(epsilon=0.001, name='bnorm_' + str(conv['layer_idx']))(x)\n",
    "\t\tif conv['leaky']: x = LeakyReLU(alpha=0.1, name='leaky_' + str(conv['layer_idx']))(x)\n",
    "\treturn add([skip_connection, x]) if skip else x\n",
    "\n",
    "def make_yolov3_model():\n",
    "\tinput_image = Input(shape=(None, None, 3))\n",
    "\t# Layer  0 => 4\n",
    "\tx = _conv_block(input_image, [{'filter': 32, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 0},\n",
    "\t\t\t\t\t\t\t\t  {'filter': 64, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 1},\n",
    "\t\t\t\t\t\t\t\t  {'filter': 32, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 2},\n",
    "\t\t\t\t\t\t\t\t  {'filter': 64, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 3}])\n",
    "\t# Layer  5 => 8\n",
    "\tx = _conv_block(x, [{'filter': 128, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 5},\n",
    "\t\t\t\t\t\t{'filter':  64, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 6},\n",
    "\t\t\t\t\t\t{'filter': 128, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 7}])\n",
    "\t# Layer  9 => 11\n",
    "\tx = _conv_block(x, [{'filter':  64, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 9},\n",
    "\t\t\t\t\t\t{'filter': 128, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 10}])\n",
    "\t# Layer 12 => 15\n",
    "\tx = _conv_block(x, [{'filter': 256, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 12},\n",
    "\t\t\t\t\t\t{'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 13},\n",
    "\t\t\t\t\t\t{'filter': 256, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 14}])\n",
    "\t# Layer 16 => 36\n",
    "\tfor i in range(7):\n",
    "\t\tx = _conv_block(x, [{'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 16+i*3},\n",
    "\t\t\t\t\t\t\t{'filter': 256, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 17+i*3}])\n",
    "\tskip_36 = x\n",
    "\t# Layer 37 => 40\n",
    "\tx = _conv_block(x, [{'filter': 512, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 37},\n",
    "\t\t\t\t\t\t{'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 38},\n",
    "\t\t\t\t\t\t{'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 39}])\n",
    "\t# Layer 41 => 61\n",
    "\tfor i in range(7):\n",
    "\t\tx = _conv_block(x, [{'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 41+i*3},\n",
    "\t\t\t\t\t\t\t{'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 42+i*3}])\n",
    "\tskip_61 = x\n",
    "\t# Layer 62 => 65\n",
    "\tx = _conv_block(x, [{'filter': 1024, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 62},\n",
    "\t\t\t\t\t\t{'filter':  512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 63},\n",
    "\t\t\t\t\t\t{'filter': 1024, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 64}])\n",
    "\t# Layer 66 => 74\n",
    "\tfor i in range(3):\n",
    "\t\tx = _conv_block(x, [{'filter':  512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 66+i*3},\n",
    "\t\t\t\t\t\t\t{'filter': 1024, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 67+i*3}])\n",
    "\t# Layer 75 => 79\n",
    "\tx = _conv_block(x, [{'filter':  512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 75},\n",
    "\t\t\t\t\t\t{'filter': 1024, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 76},\n",
    "\t\t\t\t\t\t{'filter':  512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 77},\n",
    "\t\t\t\t\t\t{'filter': 1024, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 78},\n",
    "\t\t\t\t\t\t{'filter':  512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 79}], skip=False)\n",
    "\t# Layer 80 => 82\n",
    "\tyolo_82 = _conv_block(x, [{'filter': 1024, 'kernel': 3, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 80},\n",
    "\t\t\t\t\t\t\t  {'filter':  255, 'kernel': 1, 'stride': 1, 'bnorm': False, 'leaky': False, 'layer_idx': 81}], skip=False)\n",
    "\t# Layer 83 => 86\n",
    "\tx = _conv_block(x, [{'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 84}], skip=False)\n",
    "\tx = UpSampling2D(2)(x)\n",
    "\tx = concatenate([x, skip_61])\n",
    "\t# Layer 87 => 91\n",
    "\tx = _conv_block(x, [{'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 87},\n",
    "\t\t\t\t\t\t{'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 88},\n",
    "\t\t\t\t\t\t{'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 89},\n",
    "\t\t\t\t\t\t{'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 90},\n",
    "\t\t\t\t\t\t{'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 91}], skip=False)\n",
    "\t# Layer 92 => 94\n",
    "\tyolo_94 = _conv_block(x, [{'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 92},\n",
    "\t\t\t\t\t\t\t  {'filter': 255, 'kernel': 1, 'stride': 1, 'bnorm': False, 'leaky': False, 'layer_idx': 93}], skip=False)\n",
    "\t# Layer 95 => 98\n",
    "\tx = _conv_block(x, [{'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True,   'layer_idx': 96}], skip=False)\n",
    "\tx = UpSampling2D(2)(x)\n",
    "\tx = concatenate([x, skip_36])\n",
    "\t# Layer 99 => 106\n",
    "\tyolo_106 = _conv_block(x, [{'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 99},\n",
    "\t\t\t\t\t\t\t   {'filter': 256, 'kernel': 3, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 100},\n",
    "\t\t\t\t\t\t\t   {'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 101},\n",
    "\t\t\t\t\t\t\t   {'filter': 256, 'kernel': 3, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 102},\n",
    "\t\t\t\t\t\t\t   {'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 103},\n",
    "\t\t\t\t\t\t\t   {'filter': 256, 'kernel': 3, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 104},\n",
    "\t\t\t\t\t\t\t   {'filter': 255, 'kernel': 1, 'stride': 1, 'bnorm': False, 'leaky': False, 'layer_idx': 105}], skip=False)\n",
    "\tmodel = Model(input_image, [yolo_82, yolo_94, yolo_106])\n",
    "\treturn model\n",
    "\n",
    "class WeightReader:\n",
    "\tdef __init__(self, weight_file):\n",
    "\t\twith open(weight_file, 'rb') as w_f:\n",
    "\t\t\tmajor,\t= struct.unpack('i', w_f.read(4))\n",
    "\t\t\tminor,\t= struct.unpack('i', w_f.read(4))\n",
    "\t\t\trevision, = struct.unpack('i', w_f.read(4))\n",
    "\t\t\tif (major*10 + minor) >= 2 and major < 1000 and minor < 1000:\n",
    "\t\t\t\tw_f.read(8)\n",
    "\t\t\telse:\n",
    "\t\t\t\tw_f.read(4)\n",
    "\t\t\ttranspose = (major > 1000) or (minor > 1000)\n",
    "\t\t\tbinary = w_f.read()\n",
    "\t\tself.offset = 0\n",
    "\t\tself.all_weights = np.frombuffer(binary, dtype='float32')\n",
    "\n",
    "\tdef read_bytes(self, size):\n",
    "\t\tself.offset = self.offset + size\n",
    "\t\treturn self.all_weights[self.offset-size:self.offset]\n",
    "\n",
    "\tdef load_weights(self, model):\n",
    "\t\tfor i in range(106):\n",
    "\t\t\ttry:\n",
    "\t\t\t\tconv_layer = model.get_layer('conv_' + str(i))\n",
    "\t\t\t\tprint(\"loading weights of convolution #\" + str(i))\n",
    "\t\t\t\tif i not in [81, 93, 105]:\n",
    "\t\t\t\t\tnorm_layer = model.get_layer('bnorm_' + str(i))\n",
    "\t\t\t\t\tsize = np.prod(norm_layer.get_weights()[0].shape)\n",
    "\t\t\t\t\tbeta  = self.read_bytes(size) # bias\n",
    "\t\t\t\t\tgamma = self.read_bytes(size) # scale\n",
    "\t\t\t\t\tmean  = self.read_bytes(size) # mean\n",
    "\t\t\t\t\tvar   = self.read_bytes(size) # variance\n",
    "\t\t\t\t\tweights = norm_layer.set_weights([gamma, beta, mean, var])\n",
    "\t\t\t\tif len(conv_layer.get_weights()) > 1:\n",
    "\t\t\t\t\tbias   = self.read_bytes(np.prod(conv_layer.get_weights()[1].shape))\n",
    "\t\t\t\t\tkernel = self.read_bytes(np.prod(conv_layer.get_weights()[0].shape))\n",
    "\t\t\t\t\tkernel = kernel.reshape(list(reversed(conv_layer.get_weights()[0].shape)))\n",
    "\t\t\t\t\tkernel = kernel.transpose([2,3,1,0])\n",
    "\t\t\t\t\tconv_layer.set_weights([kernel, bias])\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tkernel = self.read_bytes(np.prod(conv_layer.get_weights()[0].shape))\n",
    "\t\t\t\t\tkernel = kernel.reshape(list(reversed(conv_layer.get_weights()[0].shape)))\n",
    "\t\t\t\t\tkernel = kernel.transpose([2,3,1,0])\n",
    "\t\t\t\t\tconv_layer.set_weights([kernel])\n",
    "\t\t\texcept ValueError:\n",
    "\t\t\t\tprint(\"no convolution #\" + str(i))\n",
    "\n",
    "\tdef reset(self):\n",
    "\t\tself.offset = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b07d090-95ad-4d38-bf74-73ac29aba903",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading weights of convolution #0\n",
      "loading weights of convolution #1\n",
      "loading weights of convolution #2\n",
      "loading weights of convolution #3\n",
      "no convolution #4\n",
      "loading weights of convolution #5\n",
      "loading weights of convolution #6\n",
      "loading weights of convolution #7\n",
      "no convolution #8\n",
      "loading weights of convolution #9\n",
      "loading weights of convolution #10\n",
      "no convolution #11\n",
      "loading weights of convolution #12\n",
      "loading weights of convolution #13\n",
      "loading weights of convolution #14\n",
      "no convolution #15\n",
      "loading weights of convolution #16\n",
      "loading weights of convolution #17\n",
      "no convolution #18\n",
      "loading weights of convolution #19\n",
      "loading weights of convolution #20\n",
      "no convolution #21\n",
      "loading weights of convolution #22\n",
      "loading weights of convolution #23\n",
      "no convolution #24\n",
      "loading weights of convolution #25\n",
      "loading weights of convolution #26\n",
      "no convolution #27\n",
      "loading weights of convolution #28\n",
      "loading weights of convolution #29\n",
      "no convolution #30\n",
      "loading weights of convolution #31\n",
      "loading weights of convolution #32\n",
      "no convolution #33\n",
      "loading weights of convolution #34\n",
      "loading weights of convolution #35\n",
      "no convolution #36\n",
      "loading weights of convolution #37\n",
      "loading weights of convolution #38\n",
      "loading weights of convolution #39\n",
      "no convolution #40\n",
      "loading weights of convolution #41\n",
      "loading weights of convolution #42\n",
      "no convolution #43\n",
      "loading weights of convolution #44\n",
      "loading weights of convolution #45\n",
      "no convolution #46\n",
      "loading weights of convolution #47\n",
      "loading weights of convolution #48\n",
      "no convolution #49\n",
      "loading weights of convolution #50\n",
      "loading weights of convolution #51\n",
      "no convolution #52\n",
      "loading weights of convolution #53\n",
      "loading weights of convolution #54\n",
      "no convolution #55\n",
      "loading weights of convolution #56\n",
      "loading weights of convolution #57\n",
      "no convolution #58\n",
      "loading weights of convolution #59\n",
      "loading weights of convolution #60\n",
      "no convolution #61\n",
      "loading weights of convolution #62\n",
      "loading weights of convolution #63\n",
      "loading weights of convolution #64\n",
      "no convolution #65\n",
      "loading weights of convolution #66\n",
      "loading weights of convolution #67\n",
      "no convolution #68\n",
      "loading weights of convolution #69\n",
      "loading weights of convolution #70\n",
      "no convolution #71\n",
      "loading weights of convolution #72\n",
      "loading weights of convolution #73\n",
      "no convolution #74\n",
      "loading weights of convolution #75\n",
      "loading weights of convolution #76\n",
      "loading weights of convolution #77\n",
      "loading weights of convolution #78\n",
      "loading weights of convolution #79\n",
      "loading weights of convolution #80\n",
      "loading weights of convolution #81\n",
      "no convolution #82\n",
      "no convolution #83\n",
      "loading weights of convolution #84\n",
      "no convolution #85\n",
      "no convolution #86\n",
      "loading weights of convolution #87\n",
      "loading weights of convolution #88\n",
      "loading weights of convolution #89\n",
      "loading weights of convolution #90\n",
      "loading weights of convolution #91\n",
      "loading weights of convolution #92\n",
      "loading weights of convolution #93\n",
      "no convolution #94\n",
      "no convolution #95\n",
      "loading weights of convolution #96\n",
      "no convolution #97\n",
      "no convolution #98\n",
      "loading weights of convolution #99\n",
      "loading weights of convolution #100\n",
      "loading weights of convolution #101\n",
      "loading weights of convolution #102\n",
      "loading weights of convolution #103\n",
      "loading weights of convolution #104\n",
      "loading weights of convolution #105\n"
     ]
    }
   ],
   "source": [
    "# define the model\n",
    "model = make_yolov3_model()\n",
    "\n",
    "# load the model weights\n",
    "# yolov3.weights can be downloaded from https://github.com/patrick013/Object-Detection---Yolov3/blob/master/model/yolov3.weights\n",
    "weight_reader = WeightReader('/n/holylfs05/LABS/jyang_lab/Lab/tiktok_sample/sales_panel/yolov3.weights')\n",
    "\n",
    "# set the model weights into the model\n",
    "weight_reader.load_weights(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0da2cf5-0197-406a-b8a0-ddc9e8aadc8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import expand_dims\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from matplotlib import pyplot\n",
    "from matplotlib.patches import Rectangle\n",
    "\n",
    "class BoundBox:\n",
    "\tdef __init__(self, xmin, ymin, xmax, ymax, objness = None, classes = None):\n",
    "\t\tself.xmin = xmin\n",
    "\t\tself.ymin = ymin\n",
    "\t\tself.xmax = xmax\n",
    "\t\tself.ymax = ymax\n",
    "\t\tself.objness = objness\n",
    "\t\tself.classes = classes\n",
    "\t\tself.label = -1\n",
    "\t\tself.score = -1\n",
    "\n",
    "\tdef get_label(self):\n",
    "\t\tif self.label == -1:\n",
    "\t\t\tself.label = np.argmax(self.classes)\n",
    "\n",
    "\t\treturn self.label\n",
    "\n",
    "\tdef get_score(self):\n",
    "\t\tif self.score == -1:\n",
    "\t\t\tself.score = self.classes[self.get_label()]\n",
    "\n",
    "\t\treturn self.score\n",
    "\n",
    "def _sigmoid(x):\n",
    "\treturn 1. / (1. + np.exp(-x))\n",
    "\n",
    "def decode_netout(netout, anchors, obj_thresh, net_h, net_w):\n",
    "\tgrid_h, grid_w = netout.shape[:2]\n",
    "\tnb_box = 3\n",
    "\tnetout = netout.reshape((grid_h, grid_w, nb_box, -1))\n",
    "\tnb_class = netout.shape[-1] - 5\n",
    "\tboxes = []\n",
    "\tnetout[..., :2]  = _sigmoid(netout[..., :2])\n",
    "\tnetout[..., 4:]  = _sigmoid(netout[..., 4:])\n",
    "\tnetout[..., 5:]  = netout[..., 4][..., np.newaxis] * netout[..., 5:]\n",
    "\tnetout[..., 5:] *= netout[..., 5:] > obj_thresh\n",
    "\n",
    "\tfor i in range(grid_h*grid_w):\n",
    "\t\trow = i / grid_w\n",
    "\t\tcol = i % grid_w\n",
    "\t\tfor b in range(nb_box):\n",
    "\t\t\t# 4th element is objectness score\n",
    "\t\t\tobjectness = netout[int(row)][int(col)][b][4]\n",
    "\t\t\tif(objectness.all() <= obj_thresh): continue\n",
    "\t\t\t# first 4 elements are x, y, w, and h\n",
    "\t\t\tx, y, w, h = netout[int(row)][int(col)][b][:4]\n",
    "\t\t\tx = (col + x) / grid_w # center position, unit: image width\n",
    "\t\t\ty = (row + y) / grid_h # center position, unit: image height\n",
    "\t\t\tw = anchors[2 * b + 0] * np.exp(w) / net_w # unit: image width\n",
    "\t\t\th = anchors[2 * b + 1] * np.exp(h) / net_h # unit: image height\n",
    "\t\t\t# last elements are class probabilities\n",
    "\t\t\tclasses = netout[int(row)][col][b][5:]\n",
    "\t\t\tbox = BoundBox(x-w/2, y-h/2, x+w/2, y+h/2, objectness, classes)\n",
    "\t\t\tboxes.append(box)\n",
    "\treturn boxes\n",
    "\n",
    "def correct_yolo_boxes(boxes, image_h, image_w, net_h, net_w):\n",
    "\tnew_w, new_h = net_w, net_h\n",
    "\tfor i in range(len(boxes)):\n",
    "\t\tx_offset, x_scale = (net_w - new_w)/2./net_w, float(new_w)/net_w\n",
    "\t\ty_offset, y_scale = (net_h - new_h)/2./net_h, float(new_h)/net_h\n",
    "\t\tboxes[i].xmin = int((boxes[i].xmin - x_offset) / x_scale * image_w)\n",
    "\t\tboxes[i].xmax = int((boxes[i].xmax - x_offset) / x_scale * image_w)\n",
    "\t\tboxes[i].ymin = int((boxes[i].ymin - y_offset) / y_scale * image_h)\n",
    "\t\tboxes[i].ymax = int((boxes[i].ymax - y_offset) / y_scale * image_h)\n",
    "\n",
    "def _interval_overlap(interval_a, interval_b):\n",
    "\tx1, x2 = interval_a\n",
    "\tx3, x4 = interval_b\n",
    "\tif x3 < x1:\n",
    "\t\tif x4 < x1:\n",
    "\t\t\treturn 0\n",
    "\t\telse:\n",
    "\t\t\treturn min(x2,x4) - x1\n",
    "\telse:\n",
    "\t\tif x2 < x3:\n",
    "\t\t\t return 0\n",
    "\t\telse:\n",
    "\t\t\treturn min(x2,x4) - x3\n",
    "\n",
    "def bbox_iou(box1, box2):\n",
    "\tintersect_w = _interval_overlap([box1.xmin, box1.xmax], [box2.xmin, box2.xmax])\n",
    "\tintersect_h = _interval_overlap([box1.ymin, box1.ymax], [box2.ymin, box2.ymax])\n",
    "\tintersect = intersect_w * intersect_h\n",
    "\tw1, h1 = box1.xmax-box1.xmin, box1.ymax-box1.ymin\n",
    "\tw2, h2 = box2.xmax-box2.xmin, box2.ymax-box2.ymin\n",
    "\tunion = w1*h1 + w2*h2 - intersect\n",
    "\treturn float(intersect) / union\n",
    "\n",
    "def do_nms(boxes, nms_thresh):\n",
    "\tif len(boxes) > 0:\n",
    "\t\tnb_class = len(boxes[0].classes)\n",
    "\telse:\n",
    "\t\treturn\n",
    "\tfor c in range(nb_class):\n",
    "\t\tsorted_indices = np.argsort([-box.classes[c] for box in boxes])\n",
    "\t\tfor i in range(len(sorted_indices)):\n",
    "\t\t\tindex_i = sorted_indices[i]\n",
    "\t\t\tif boxes[index_i].classes[c] == 0: continue\n",
    "\t\t\tfor j in range(i+1, len(sorted_indices)):\n",
    "\t\t\t\tindex_j = sorted_indices[j]\n",
    "\t\t\t\tif bbox_iou(boxes[index_i], boxes[index_j]) >= nms_thresh:\n",
    "\t\t\t\t\tboxes[index_j].classes[c] = 0\n",
    "\n",
    "# get all of the results above a threshold\n",
    "def get_boxes(boxes, labels, thresh):\n",
    "\tv_boxes, v_labels, v_scores = list(), list(), list()\n",
    "\t# enumerate all boxes\n",
    "\tfor box in boxes:\n",
    "\t\t# enumerate all possible labels\n",
    "\t\tfor i in range(len(labels)):\n",
    "\t\t\t# check if the threshold for this label is high enough\n",
    "\t\t\tif box.classes[i] > thresh:\n",
    "\t\t\t\tv_boxes.append(box)\n",
    "\t\t\t\tv_labels.append(labels[i])\n",
    "\t\t\t\tv_scores.append(box.classes[i]*100)\n",
    "\t\t\t\t# don't break, many labels may trigger for one box\n",
    "\treturn v_boxes, v_labels, v_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4c0a00b7-458e-4efe-9a3e-aa2205961d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the anchors\n",
    "anchors = [[116,90, 156,198, 373,326], [30,61, 62,45, 59,119], [10,13, 16,30, 33,23]]\n",
    "\n",
    "# define the probability threshold for detected objects\n",
    "class_threshold = 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3aea1eb9-f3c4-4dfb-bd5d-76ca98a2293d",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\"person\", \"bicycle\", \"car\", \"motorbike\", \"aeroplane\", \"bus\", \"train\", \"truck\",\n",
    "\t\"boat\", \"traffic light\", \"fire hydrant\", \"stop sign\", \"parking meter\", \"bench\",\n",
    "\t\"bird\", \"cat\", \"dog\", \"horse\", \"sheep\", \"cow\", \"elephant\", \"bear\", \"zebra\", \"giraffe\",\n",
    "\t\"backpack\", \"umbrella\", \"handbag\", \"tie\", \"suitcase\", \"frisbee\", \"skis\", \"snowboard\",\n",
    "\t\"sports ball\", \"kite\", \"baseball bat\", \"baseball glove\", \"skateboard\", \"surfboard\",\n",
    "\t\"tennis racket\", \"bottle\", \"wine glass\", \"cup\", \"fork\", \"knife\", \"spoon\", \"bowl\", \"banana\",\n",
    "\t\"apple\", \"sandwich\", \"orange\", \"broccoli\", \"carrot\", \"hot dog\", \"pizza\", \"donut\", \"cake\",\n",
    "\t\"chair\", \"sofa\", \"pottedplant\", \"bed\", \"diningtable\", \"toilet\", \"tvmonitor\", \"laptop\", \"mouse\",\n",
    "\t\"remote\", \"keyboard\", \"cell phone\", \"microwave\", \"oven\", \"toaster\", \"sink\", \"refrigerator\",\n",
    "\t\"book\", \"clock\", \"vase\", \"scissors\", \"teddy bear\", \"hair drier\", \"toothbrush\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "32bdea91-69fe-4274-b2e4-6d225f8ac414",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_high_dir = '/n/holylfs05/LABS/jyang_lab/Lab/tiktok_sample/sales_panel/frame_high_engagement/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4ff606d7-53a4-4795-b4f5-ce0180020403",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define the expected input shape for the model\n",
    "\n",
    "image_w, image_h = 224, 224\n",
    "input_w, input_h = 224, 224\n",
    "\n",
    "result = []\n",
    "\n",
    "for v in video_name:\n",
    "    \n",
    "    o = np.load(frame_high_dir + v + '.npy')\n",
    "    \n",
    "    for j in range(len(o)):\n",
    "        d = np.expand_dims(o[j], axis=0)\n",
    "        yhat = model.predict(d)\n",
    "        \n",
    "        boxes = list()\n",
    "        \n",
    "        for k in range(len(yhat)):\n",
    "            boxes += decode_netout(yhat[k][0], anchors[k], class_threshold, input_h, input_w)\n",
    "\n",
    "        correct_yolo_boxes(boxes, image_h, image_w, input_h, input_w)\n",
    "        do_nms(boxes, 0.5)\n",
    "        \n",
    "        v_boxes, v_labels, v_scores = get_boxes(boxes, labels, class_threshold)\n",
    "        \n",
    "        dic = dict(zip(v_labels, v_scores))\n",
    "        result.append(dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "952f87cb-85d0-4ef9-8dd4-0eb8c8444df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "things = []\n",
    "prob = []\n",
    "\n",
    "for i in range(len(result)):\n",
    "    d = result[i]\n",
    "    things.append(list(d.keys()))\n",
    "    prob.append(list(d.values()))\n",
    "\n",
    "things = [item for sublist in things for item in sublist]\n",
    "prob = [item for sublist in prob for item in sublist]\n",
    "\n",
    "df_high = pd.DataFrame()\n",
    "df_high['object'] = things\n",
    "df_high['prob'] = prob\n",
    "df_high.to_csv('/n/holylfs05/LABS/jyang_lab/Lab/tiktok_sample/sales_panel/object/high.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e4565b55-5619-485b-89c2-44b85428dcc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_low_dir = '/n/holylfs05/LABS/jyang_lab/Lab/tiktok_sample/sales_panel/frame_low_engagement/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "40b45daf-3337-42e8-ad95-8799dd2e4bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the expected input shape for the model\n",
    "\n",
    "image_w, image_h = 224, 224\n",
    "input_w, input_h = 224, 224\n",
    "\n",
    "result = []\n",
    "\n",
    "for v in video_name:\n",
    "    \n",
    "    o = np.load(frame_low_dir + v + '.npy')\n",
    "    \n",
    "    for j in range(len(o)):\n",
    "        d = np.expand_dims(o[j], axis=0)\n",
    "        yhat = model.predict(d)\n",
    "        \n",
    "        boxes = list()\n",
    "        \n",
    "        for k in range(len(yhat)):\n",
    "            boxes += decode_netout(yhat[k][0], anchors[k], class_threshold, input_h, input_w)\n",
    "\n",
    "        correct_yolo_boxes(boxes, image_h, image_w, input_h, input_w)\n",
    "        do_nms(boxes, 0.5)\n",
    "        \n",
    "        v_boxes, v_labels, v_scores = get_boxes(boxes, labels, class_threshold)\n",
    "        \n",
    "        dic = dict(zip(v_labels, v_scores))\n",
    "        result.append(dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2547651e-ae3d-4649-9712-f5e44b6c9ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "things = []\n",
    "prob = []\n",
    "\n",
    "for i in range(len(result)):\n",
    "    d = result[i]\n",
    "    things.append(list(d.keys()))\n",
    "    prob.append(list(d.values()))\n",
    "\n",
    "things = [item for sublist in things for item in sublist]\n",
    "prob = [item for sublist in prob for item in sublist]\n",
    "\n",
    "df_low = pd.DataFrame()\n",
    "df_low['object'] = things\n",
    "df_low['prob'] = prob\n",
    "df_low.to_csv('/n/holylfs05/LABS/jyang_lab/Lab/tiktok_sample/sales_panel/object/low.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "77b63607-6eaf-4547-88b9-a61925b784cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# py_session()\n",
    "# 63 modules found\n",
    "# IPython             \t7.22.0                  idna                \t2.10                    py_session          \t0.1.1\n",
    "# PIL                 \t8.2.0                   ipykernel           \t5.3.4                   pygments            \t2.8.1\n",
    "# argparse            \t1.1                     ipython_genutils    \t0.2.0                   pyparsing           \t2.4.7\n",
    "# astunparse          \t1.6.3                   jedi                \t0.17.2                  pytz                \t2021.1\n",
    "# backcall            \t0.2.0                   json                \t2.0.9                   re                  \t2.2.1\n",
    "# bottleneck          \t1.3.2                   jupyter_client      \t6.1.12                  requests            \t2.31.0\n",
    "# certifi             \t2020.12.05              jupyter_core        \t4.7.1                   scipy               \t1.6.2\n",
    "# cffi                \t1.14.5                  keras_preprocessing \t1.1.2                   six                 \t1.15.0\n",
    "# chardet             \t4.0.0                   kiwisolver          \t1.3.1                   skimage             \t0.18.1\n",
    "# charset_normalizer  \t3.3.2                   logging             \t0.5.1.2                 socks               \t1.7.1\n",
    "# colorama            \t0.4.4                   matplotlib          \t3.3.4                   tblib               \t1.7.0\n",
    "# csv                 \t1.0                     natsort             \t8.4.0                   tensorboard         \t2.11.2\n",
    "# ctypes              \t1.1.0                   numpy               \t1.22.4                  tensorflow          \t2.5.0\n",
    "# cv2                 \t4.8.1                   opt_einsum          \tv3.3.0                  termcolor           \t(1, 1, 0)\n",
    "# cycler              \t0.10.0                  pandas              \t1.2.4                   traitlets           \t5.0.5\n",
    "# dateutil            \t2.8.1                   parso               \t0.7.0                   urllib3             \t1.26.4\n",
    "# decimal             \t1.70                    pexpect             \t4.8.0                   wcwidth             \t0.2.5\n",
    "# decorator           \t4.4.2                   pickleshare         \t0.7.5                   wrapt               \t1.12.1\n",
    "# distutils           \t3.8.8                   platform            \t1.0.8                   yaml                \t5.4.1\n",
    "# fsspec              \t0.9.0                   prompt_toolkit      \t3.0.17                  zlib                \t1.0\n",
    "# h5py                \t3.1.0                   ptyprocess          \t0.7.0                   zmq                 \t20.0.0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
